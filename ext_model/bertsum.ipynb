{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a25128c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from BERT.ipynb\n"
     ]
    }
   ],
   "source": [
    "from pandas import json_normalize\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm, tqdm_notebook, trange\n",
    "import sentencepiece as spm\n",
    "import wget\n",
    "import import_ipynb\n",
    "import BERT\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f391b65",
   "metadata": {},
   "source": [
    "# Fine Tune Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e4853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_original.json') as file:\n",
    "    data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7959646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = json_normalize(data['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3616ae47",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>media_type</th>\n",
       "      <th>media_sub_type</th>\n",
       "      <th>media_name</th>\n",
       "      <th>size</th>\n",
       "      <th>char_count</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>extractive</th>\n",
       "      <th>abstractive</th>\n",
       "      <th>document_quality_scores.readable</th>\n",
       "      <th>document_quality_scores.accurate</th>\n",
       "      <th>document_quality_scores.informative</th>\n",
       "      <th>document_quality_scores.trustworthy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>290741778</td>\n",
       "      <td>종합</td>\n",
       "      <td>online</td>\n",
       "      <td>지역지</td>\n",
       "      <td>광양신문</td>\n",
       "      <td>small</td>\n",
       "      <td>927</td>\n",
       "      <td>2018-01-05 18:54:55</td>\n",
       "      <td>논 타작물 재배, 2월 말까지 신청하세요</td>\n",
       "      <td>[[{'index': 0, 'sentence': 'ha당 조사료 400만원…작물별 ...</td>\n",
       "      <td>11</td>\n",
       "      <td>[2, 3, 10]</td>\n",
       "      <td>[전라남도가 쌀 과잉문제를 근본적으로 해결하기 위해 올해부터 벼를 심었던 논에 벼 ...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290741792</td>\n",
       "      <td>종합</td>\n",
       "      <td>online</td>\n",
       "      <td>지역지</td>\n",
       "      <td>광양신문</td>\n",
       "      <td>small</td>\n",
       "      <td>764</td>\n",
       "      <td>2018-01-05 18:53:20</td>\n",
       "      <td>여수시, 컬러빌리지 마무리...‘색채와 빛’도시 완성</td>\n",
       "      <td>[[{'index': 0, 'sentence': '8억 투입, 고소천사벽화·자산마을...</td>\n",
       "      <td>12</td>\n",
       "      <td>[2, 4, 11]</td>\n",
       "      <td>[여수시는 컬러빌리지 사업에 8억원을 투입하여 ‘색채와 빛’ 도시를 완성하여 고소천...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>290741793</td>\n",
       "      <td>스포츠</td>\n",
       "      <td>online</td>\n",
       "      <td>지역지</td>\n",
       "      <td>광양신문</td>\n",
       "      <td>medium</td>\n",
       "      <td>1066</td>\n",
       "      <td>2018-01-05 18:52:15</td>\n",
       "      <td>“새해 정기 받고 올해는 반드시 일내자!”</td>\n",
       "      <td>[[{'index': 0, 'sentence': '전남드래곤즈 해맞이 다짐…선수 영...</td>\n",
       "      <td>13</td>\n",
       "      <td>[3, 5, 7]</td>\n",
       "      <td>[전남드래곤즈 임직원과 선수단이 4일 구봉산 정상에 올라 일출을 보며 2018년 구...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>290741794</td>\n",
       "      <td>정치</td>\n",
       "      <td>online</td>\n",
       "      <td>지역지</td>\n",
       "      <td>광양신문</td>\n",
       "      <td>small</td>\n",
       "      <td>746</td>\n",
       "      <td>2018-01-05 18:50:17</td>\n",
       "      <td>농업인 역량 강화, 새해 실용교육 실시</td>\n",
       "      <td>[[{'index': 0, 'sentence': '11~24일, 매실·감·참다래 등...</td>\n",
       "      <td>12</td>\n",
       "      <td>[2, 3, 4]</td>\n",
       "      <td>[광양시는 농업인들의 경쟁력을 높이고, 소득안정을 위해 매실·감·참다래 등 지역특화...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>290741797</td>\n",
       "      <td>종합</td>\n",
       "      <td>online</td>\n",
       "      <td>지역지</td>\n",
       "      <td>광양신문</td>\n",
       "      <td>small</td>\n",
       "      <td>978</td>\n",
       "      <td>2018-01-05 18:52:36</td>\n",
       "      <td>타이완 크루즈관광객 4천여명‘전남’온다</td>\n",
       "      <td>[[{'index': 0, 'sentence': '홍콩 크루즈선사‘아쿠아리우스’ 4...</td>\n",
       "      <td>13</td>\n",
       "      <td>[3, 7, 4]</td>\n",
       "      <td>[올해 4월과 6월 두 차례에 걸쳐 타이완의 크루즈 관광객 4000여명이 여수에 입...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id category media_type media_sub_type media_name    size char_count  \\\n",
       "0  290741778       종합     online            지역지       광양신문   small        927   \n",
       "1  290741792       종합     online            지역지       광양신문   small        764   \n",
       "2  290741793      스포츠     online            지역지       광양신문  medium       1066   \n",
       "3  290741794       정치     online            지역지       광양신문   small        746   \n",
       "4  290741797       종합     online            지역지       광양신문   small        978   \n",
       "\n",
       "          publish_date                          title  \\\n",
       "0  2018-01-05 18:54:55         논 타작물 재배, 2월 말까지 신청하세요   \n",
       "1  2018-01-05 18:53:20  여수시, 컬러빌리지 마무리...‘색채와 빛’도시 완성   \n",
       "2  2018-01-05 18:52:15        “새해 정기 받고 올해는 반드시 일내자!”   \n",
       "3  2018-01-05 18:50:17          농업인 역량 강화, 새해 실용교육 실시   \n",
       "4  2018-01-05 18:52:36          타이완 크루즈관광객 4천여명‘전남’온다   \n",
       "\n",
       "                                                text  annotator_id  \\\n",
       "0  [[{'index': 0, 'sentence': 'ha당 조사료 400만원…작물별 ...            11   \n",
       "1  [[{'index': 0, 'sentence': '8억 투입, 고소천사벽화·자산마을...            12   \n",
       "2  [[{'index': 0, 'sentence': '전남드래곤즈 해맞이 다짐…선수 영...            13   \n",
       "3  [[{'index': 0, 'sentence': '11~24일, 매실·감·참다래 등...            12   \n",
       "4  [[{'index': 0, 'sentence': '홍콩 크루즈선사‘아쿠아리우스’ 4...            13   \n",
       "\n",
       "   extractive                                        abstractive  \\\n",
       "0  [2, 3, 10]  [전라남도가 쌀 과잉문제를 근본적으로 해결하기 위해 올해부터 벼를 심었던 논에 벼 ...   \n",
       "1  [2, 4, 11]  [여수시는 컬러빌리지 사업에 8억원을 투입하여 ‘색채와 빛’ 도시를 완성하여 고소천...   \n",
       "2   [3, 5, 7]  [전남드래곤즈 임직원과 선수단이 4일 구봉산 정상에 올라 일출을 보며 2018년 구...   \n",
       "3   [2, 3, 4]  [광양시는 농업인들의 경쟁력을 높이고, 소득안정을 위해 매실·감·참다래 등 지역특화...   \n",
       "4   [3, 7, 4]  [올해 4월과 6월 두 차례에 걸쳐 타이완의 크루즈 관광객 4000여명이 여수에 입...   \n",
       "\n",
       "   document_quality_scores.readable  document_quality_scores.accurate  \\\n",
       "0                                 4                                 3   \n",
       "1                                 4                                 4   \n",
       "2                                 4                                 4   \n",
       "3                                 4                                 4   \n",
       "4                                 4                                 4   \n",
       "\n",
       "   document_quality_scores.informative  document_quality_scores.trustworthy  \n",
       "0                                    3                                    3  \n",
       "1                                    5                                    4  \n",
       "2                                    4                                    4  \n",
       "3                                    5                                    4  \n",
       "4                                    4                                    4  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2439a143",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>extractive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>논 타작물 재배, 2월 말까지 신청하세요</td>\n",
       "      <td>[[{'index': 0, 'sentence': 'ha당 조사료 400만원…작물별 ...</td>\n",
       "      <td>[2, 3, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>여수시, 컬러빌리지 마무리...‘색채와 빛’도시 완성</td>\n",
       "      <td>[[{'index': 0, 'sentence': '8억 투입, 고소천사벽화·자산마을...</td>\n",
       "      <td>[2, 4, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“새해 정기 받고 올해는 반드시 일내자!”</td>\n",
       "      <td>[[{'index': 0, 'sentence': '전남드래곤즈 해맞이 다짐…선수 영...</td>\n",
       "      <td>[3, 5, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>농업인 역량 강화, 새해 실용교육 실시</td>\n",
       "      <td>[[{'index': 0, 'sentence': '11~24일, 매실·감·참다래 등...</td>\n",
       "      <td>[2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>타이완 크루즈관광객 4천여명‘전남’온다</td>\n",
       "      <td>[[{'index': 0, 'sentence': '홍콩 크루즈선사‘아쿠아리우스’ 4...</td>\n",
       "      <td>[3, 7, 4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title  \\\n",
       "0         논 타작물 재배, 2월 말까지 신청하세요   \n",
       "1  여수시, 컬러빌리지 마무리...‘색채와 빛’도시 완성   \n",
       "2        “새해 정기 받고 올해는 반드시 일내자!”   \n",
       "3          농업인 역량 강화, 새해 실용교육 실시   \n",
       "4          타이완 크루즈관광객 4천여명‘전남’온다   \n",
       "\n",
       "                                                text  extractive  \n",
       "0  [[{'index': 0, 'sentence': 'ha당 조사료 400만원…작물별 ...  [2, 3, 10]  \n",
       "1  [[{'index': 0, 'sentence': '8억 투입, 고소천사벽화·자산마을...  [2, 4, 11]  \n",
       "2  [[{'index': 0, 'sentence': '전남드래곤즈 해맞이 다짐…선수 영...   [3, 5, 7]  \n",
       "3  [[{'index': 0, 'sentence': '11~24일, 매실·감·참다래 등...   [2, 3, 4]  \n",
       "4  [[{'index': 0, 'sentence': '홍콩 크루즈선사‘아쿠아리우스’ 4...   [3, 7, 4]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['title','text','extractive']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7b5860a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_file = \"/home/studio/바탕화면/web-crawler/kowiki/vocab_32000/kowiki.model\"\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ef348eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(vocab, infile, outfile):\n",
    "    with open(infile) as file:\n",
    "        data = json.load(file)\n",
    "    df = json_normalize(data['documents'])\n",
    "    df = df[['title','text','extractive']]\n",
    "    label=0\n",
    "    with open(outfile, 'w') as file:\n",
    "        for index,ext in enumerate(tqdm(df['extractive'])):\n",
    "            count=0\n",
    "            for i, text in enumerate(df['text'][index]):\n",
    "                try:\n",
    "                    for i_ in range(len(text)):\n",
    "                        sentence_=text[i_]['sentence']\n",
    "                        if len(sentence_)>500:\n",
    "                            sentence_ = sentence_[len(sentence_)-500:len(sentence_)]\n",
    "                        text_=vocab.encode_as_pieces(sentence_)\n",
    "                        if count in ext:\n",
    "                            label=1\n",
    "                        else:\n",
    "                            label=0\n",
    "                        instance = {\"id\":count, \"text\":text_, \"label\":label}\n",
    "                        file.write(json.dumps(instance))\n",
    "                        file.write(\"\\n\")\n",
    "                        count+=1\n",
    "                except:\n",
    "                    print(index,i)\n",
    "                    continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "585909f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 243983/243983 [02:20<00:00, 1737.57it/s]\n",
      "100%|███████████████████████████████████| 30122/30122 [00:16<00:00, 1776.93it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocess_data(vocab, \"train_original.json\", \"preprocess_train_original.json\")\n",
    "preprocess_data(vocab, \"valid_original.json\", \"preprecess_valid_original.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4f5085",
   "metadata": {},
   "source": [
    "# 코드 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f20c1fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import json_normalize\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm, tqdm_notebook, trange\n",
    "import sentencepiece as spm\n",
    "import wget\n",
    "import import_ipynb\n",
    "import BERT\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e57e2704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_file = \"/home/studio/바탕화면/web-crawler/kowiki/vocab_32000/kowiki.model\"\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b6cd081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary classification\n",
    "class ExtractiveClassification(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.bert = BERT.BERT(self.config)\n",
    "        # classfier\n",
    "        self.projection_cls = nn.Linear(self.config.d_model, self.config.n_output, bias=False)\n",
    "    \n",
    "    def forward(self, inputs, segments):\n",
    "        # (bs, n_enc_seq, d_hidn), (bs, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
    "        outputs, outputs_cls, attn_probs = self.bert(inputs, segments)\n",
    "        # (bs, n_output)\n",
    "        logits_cls = self.projection_cls(outputs_cls)\n",
    "        # (bs, n_output), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
    "        return logits_cls, attn_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aeff50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, vocab, infile):\n",
    "        self.vocab = vocab\n",
    "        self.labels = []\n",
    "        self.sentences = []\n",
    "        self.segments = []\n",
    "\n",
    "        line_cnt = 0\n",
    "        with open(infile, \"r\") as f:\n",
    "            for line in f:\n",
    "                line_cnt += 1\n",
    "\n",
    "        with open(infile, \"r\") as f:\n",
    "            for i, line in enumerate(tqdm(f, total=line_cnt, desc=\"Loading Dataset\", unit=\" lines\")):\n",
    "                data = json.loads(line)\n",
    "                self.labels.append(data[\"label\"])\n",
    "                sentence = [vocab.piece_to_id(\"[CLS]\")] + [vocab.piece_to_id(p) for p in data[\"text\"]] + [vocab.piece_to_id(\"[SEP]\")]\n",
    "                self.sentences.append(sentence)\n",
    "                self.segments.append([i%2] * len(sentence))\n",
    "    \n",
    "    def __len__(self):\n",
    "        assert len(self.labels) == len(self.sentences)\n",
    "        assert len(self.labels) == len(self.segments)\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return (torch.tensor(self.labels[item]),\n",
    "                torch.tensor(self.sentences[item]),\n",
    "                torch.tensor(self.segments[item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e80a5436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EXT_collate_fn(inputs):\n",
    "    labels, inputs, segments = list(zip(*inputs))\n",
    "\n",
    "    inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n",
    "    segments = torch.nn.utils.rnn.pad_sequence(segments, batch_first=True, padding_value=0)\n",
    "\n",
    "    batch = [\n",
    "        torch.stack(labels, dim=0),\n",
    "        inputs,\n",
    "        segments,\n",
    "    ]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b26c41e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset: 100%|█████████| 3495621/3495621 [01:31<00:00, 38371.34 lines/s]\n",
      "Loading Dataset: 100%|███████████| 441161/441161 [00:10<00:00, 42780.32 lines/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "train_dataset = ExtDataSet(vocab, f\"preprocess_train_original.json\")\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=EXT_collate_fn)\n",
    "test_dataset = ExtDataSet(vocab, f\"preprecess_valid_original.json\")\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=EXT_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a5093a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(config, model, data_loader):\n",
    "    matchs = []\n",
    "    model.eval()\n",
    "\n",
    "    n_word_total = 0\n",
    "    n_correct_total = 0\n",
    "    with tqdm(total=len(data_loader), desc=f\"Valid\") as pbar:\n",
    "        for i, value in enumerate(data_loader):\n",
    "            labels, inputs, segments = map(lambda v: v.to(config.device), value)\n",
    "\n",
    "            outputs = model(inputs, segments)\n",
    "            logits_cls = outputs[0]\n",
    "            _, indices = logits_cls.max(1)\n",
    "\n",
    "            match = torch.eq(indices, labels).detach()\n",
    "            matchs.extend(match.cpu())\n",
    "            accuracy = np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0\n",
    "\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix_str(f\"Acc: {accuracy:.3f}\")\n",
    "    return np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "007e088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(config, epoch, model, criterion_cls, optimizer, train_loader):\n",
    "    losses = []\n",
    "    model.train()\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n",
    "        for i, value in enumerate(train_loader):\n",
    "            labels, inputs, segments = map(lambda v: v.to(config.device), value)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs, segments)\n",
    "            logits_cls = outputs[0]\n",
    "\n",
    "            loss_cls = criterion_cls(logits_cls, labels)\n",
    "            loss = loss_cls\n",
    "\n",
    "            loss_val = loss_cls.item()\n",
    "            losses.append(loss_val)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "201220b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict): \n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file):\n",
    "        with open(file, 'r') as f:\n",
    "            config = json.loads(f.read())\n",
    "            return Config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c258c02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_enc_vocab': 32007, 'n_enc_seq': 512, 'n_seg_type': 2, 'n_layer': 6, 'd_model': 512, 'i_pad': 0, 'd_ff': 1024, 'n_head': 6, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"
     ]
    }
   ],
   "source": [
    "config = Config({\n",
    "    \"n_enc_vocab\": len(vocab), # vocab 크기\n",
    "    \"n_enc_seq\": 512,          # 글자 최대 길이 \n",
    "    \"n_seg_type\": 2,           # Segment Embedding Type  \n",
    "    \"n_layer\":6,             # layer 캣수\n",
    "    \"d_model\": 512,            # hidden layer \n",
    "    \"i_pad\": 0,                # padding 값\n",
    "    \"d_ff\": 1024,              # feedforward layer에 들어갈 차원의 크기\n",
    "    \"n_head\": 6,              # attention 개수\n",
    "    \"d_head\": 64,              # attention 차원 \n",
    "    \"dropout\": 0.1,            # dropout\n",
    "    \"layer_norm_epsilon\": 1e-12 # 정규화\n",
    "})\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "349ccabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_enc_vocab': 32007, 'n_enc_seq': 512, 'n_seg_type': 2, 'n_layer': 6, 'd_model': 512, 'i_pad': 0, 'd_ff': 1024, 'n_head': 6, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': device(type='cuda'), 'n_output': 2}\n"
     ]
    }
   ],
   "source": [
    "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "config.n_output = 2\n",
    "print(config)\n",
    "\n",
    "learning_rate = 5e-5\n",
    "n_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "981d7542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    model.to(config.device)\n",
    "\n",
    "    criterion_cls = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_epoch, best_loss, best_score = 0, 0, 0\n",
    "    losses, scores = [], []\n",
    "    for epoch in range(n_epoch):\n",
    "        loss = train_epoch(config, epoch, model, criterion_cls, optimizer, train_loader)\n",
    "        score = eval_epoch(config, model, test_loader)\n",
    "\n",
    "        losses.append(loss)\n",
    "        scores.append(score)\n",
    "\n",
    "        if best_score < score:\n",
    "            best_epoch, best_loss, best_score = epoch, loss, score\n",
    "            print(\"save : \")\n",
    "            torch.save(model.state_dict(), f'finetune_model{best_score}.pt')\n",
    "    print(f\">>>> epoch={best_epoch}, loss={best_loss:.5f}, socre={best_score:.5f}\")\n",
    "    return losses, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11c65efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train(0): 100%|██████| 54620/54620 [43:04<00:00, 21.14it/s, Loss: 0.280 (0.389)]\n",
      "Valid: 100%|████████████████████| 6894/6894 [35:38<00:00,  3.22it/s, Acc: 0.840]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train(1): 100%|██████| 54620/54620 [43:02<00:00, 21.15it/s, Loss: 0.541 (0.379)]\n",
      "Valid: 100%|████████████████████| 6894/6894 [35:45<00:00,  3.21it/s, Acc: 0.840]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train(2): 100%|██████| 54620/54620 [43:02<00:00, 21.15it/s, Loss: 0.272 (0.375)]\n",
      "Valid: 100%|████████████████████| 6894/6894 [35:41<00:00,  3.22it/s, Acc: 0.836]\n",
      "Train(3): 100%|██████| 54620/54620 [42:59<00:00, 21.17it/s, Loss: 0.133 (0.371)]\n",
      "Valid: 100%|████████████████████| 6894/6894 [35:40<00:00,  3.22it/s, Acc: 0.837]\n",
      "Train(4): 100%|██████| 54620/54620 [43:02<00:00, 21.15it/s, Loss: 1.023 (0.367)]\n",
      "Valid: 100%|████████████████████| 6894/6894 [35:43<00:00,  3.22it/s, Acc: 0.837]\n",
      "Train(5): 100%|██████| 54620/54620 [42:58<00:00, 21.18it/s, Loss: 0.133 (0.363)]\n",
      "Valid: 100%|████████████████████| 6894/6894 [35:42<00:00,  3.22it/s, Acc: 0.838]\n",
      "Train(6): 100%|██████| 54620/54620 [43:01<00:00, 21.16it/s, Loss: 0.651 (0.359)]\n",
      "Valid: 100%|████████████████████| 6894/6894 [35:42<00:00,  3.22it/s, Acc: 0.829]\n",
      "Train(7):  67%|████  | 36452/54620 [28:31<14:12, 21.30it/s, Loss: 0.296 (0.353)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12765/47303803.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtractiveClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'finetune_model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'finetune_model_last.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_12765/1173449778.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_12765/3829473819.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(config, epoch, model, criterion_cls, optimizer, train_loader)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/project/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/project/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model = ExtractiveClassification(config).to(config.device)\n",
    "model.load_state_dict(torch.load('finetune_model.pt'))\n",
    "losses, scores = train(model)\n",
    "torch.save(model.state_dict(), f'finetune_model_last.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec439036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'finetune_model_last.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "580aaa08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MovieClassification(\n",
       "  (bert): BERT(\n",
       "    (encoder): Encoder(\n",
       "      (enc_emb): Embedding(32007, 512)\n",
       "      (pos_emb): Embedding(513, 512)\n",
       "      (seg_emb): Embedding(2, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0): EncoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (W_Q): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_K): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_V): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (scaled_dot_attn): ScaledDotProductAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (linear): Linear(in_features=384, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "          (pos_ffn): PoswiseFeedForwardNet(\n",
       "            (conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "            (conv2): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): EncoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (W_Q): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_K): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_V): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (scaled_dot_attn): ScaledDotProductAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (linear): Linear(in_features=384, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "          (pos_ffn): PoswiseFeedForwardNet(\n",
       "            (conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "            (conv2): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): EncoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (W_Q): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_K): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_V): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (scaled_dot_attn): ScaledDotProductAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (linear): Linear(in_features=384, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "          (pos_ffn): PoswiseFeedForwardNet(\n",
       "            (conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "            (conv2): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): EncoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (W_Q): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_K): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_V): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (scaled_dot_attn): ScaledDotProductAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (linear): Linear(in_features=384, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "          (pos_ffn): PoswiseFeedForwardNet(\n",
       "            (conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "            (conv2): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): EncoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (W_Q): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_K): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_V): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (scaled_dot_attn): ScaledDotProductAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (linear): Linear(in_features=384, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "          (pos_ffn): PoswiseFeedForwardNet(\n",
       "            (conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "            (conv2): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): EncoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (W_Q): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_K): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_V): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (scaled_dot_attn): ScaledDotProductAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (linear): Linear(in_features=384, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "          (pos_ffn): PoswiseFeedForwardNet(\n",
       "            (conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "            (conv2): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (projection_cls): Linear(in_features=512, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15e7938",
   "metadata": {},
   "source": [
    "# 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6044e9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import json_normalize\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm, tqdm_notebook, trange\n",
    "import sentencepiece as spm\n",
    "import wget\n",
    "import import_ipynb\n",
    "import BERT\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4801dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_file = \"/home/studio/바탕화면/web-crawler/kowiki/vocab_32000/kowiki.model\"\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18b6990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractiveClassification(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.bert = BERT.BERT(self.config)\n",
    "        # classfier\n",
    "        self.projection_cls = nn.Linear(self.config.d_model, self.config.n_output, bias=False)\n",
    "    \n",
    "    def forward(self, inputs, segments):\n",
    "        # (bs, n_enc_seq, d_hidn), (bs, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
    "        outputs, outputs_cls, attn_probs = self.bert(inputs, segments)\n",
    "        # (bs, n_output)\n",
    "        logits_cls = self.projection_cls(outputs_cls)\n",
    "        # (bs, n_output), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
    "        return logits_cls, attn_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f985a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict): \n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file):\n",
    "        with open(file, 'r') as f:\n",
    "            config = json.loads(f.read())\n",
    "            return Config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6542b9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_enc_vocab': 32007, 'n_enc_seq': 512, 'n_seg_type': 2, 'n_layer': 6, 'd_model': 512, 'i_pad': 0, 'd_ff': 1024, 'n_head': 6, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': device(type='cuda'), 'n_output': 2}\n"
     ]
    }
   ],
   "source": [
    "config = Config({\n",
    "    \"n_enc_vocab\": len(vocab), # vocab 크기\n",
    "    \"n_enc_seq\": 512,          # 글자 최대 길이 \n",
    "    \"n_seg_type\": 2,           # Segment Embedding Type  \n",
    "    \"n_layer\":6,             # layer 캣수\n",
    "    \"d_model\": 512,            # hidden layer \n",
    "    \"i_pad\": 0,                # padding 값\n",
    "    \"d_ff\": 1024,              # feedforward layer에 들어갈 차원의 크기\n",
    "    \"n_head\": 6,              # attention 개수\n",
    "    \"d_head\": 64,              # attention 차원 \n",
    "    \"dropout\": 0.1,            # dropout\n",
    "    \"layer_norm_epsilon\": 1e-12 # 정규화\n",
    "})\n",
    "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "config.n_output = 2\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9eae1798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "test_model = ExtractiveClassification(config).to(config.device)\n",
    "test_model.load_state_dict(torch.load('finetune_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e72d973",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtractiveClassification(\n",
       "  (bert): BERT(\n",
       "    (encoder): Encoder(\n",
       "      (enc_emb): Embedding(32007, 512)\n",
       "      (pos_emb): Embedding(513, 512)\n",
       "      (seg_emb): Embedding(2, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0): EncoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (W_Q): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_K): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_V): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (scaled_dot_attn): ScaledDotProductAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (linear): Linear(in_features=384, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "          (pos_ffn): PoswiseFeedForwardNet(\n",
       "            (conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "            (conv2): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): EncoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (W_Q): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_K): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_V): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (scaled_dot_attn): ScaledDotProductAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (linear): Linear(in_features=384, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "          (pos_ffn): PoswiseFeedForwardNet(\n",
       "            (conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "            (conv2): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): EncoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (W_Q): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_K): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_V): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (scaled_dot_attn): ScaledDotProductAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (linear): Linear(in_features=384, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "          (pos_ffn): PoswiseFeedForwardNet(\n",
       "            (conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "            (conv2): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): EncoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (W_Q): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_K): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_V): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (scaled_dot_attn): ScaledDotProductAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (linear): Linear(in_features=384, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "          (pos_ffn): PoswiseFeedForwardNet(\n",
       "            (conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "            (conv2): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): EncoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (W_Q): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_K): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_V): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (scaled_dot_attn): ScaledDotProductAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (linear): Linear(in_features=384, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "          (pos_ffn): PoswiseFeedForwardNet(\n",
       "            (conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "            (conv2): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): EncoderLayer(\n",
       "          (self_attn): MultiHeadAttention(\n",
       "            (W_Q): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_K): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (W_V): Linear(in_features=512, out_features=384, bias=True)\n",
       "            (scaled_dot_attn): ScaledDotProductAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (linear): Linear(in_features=384, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "          (pos_ffn): PoswiseFeedForwardNet(\n",
       "            (conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "            (conv2): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (projection_cls): Linear(in_features=512, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b6e494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max(text):\n",
    "    text_index = []\n",
    "    text_value = []\n",
    "    for i in range(10):\n",
    "        t1,t2 = output_index(test_news(text_split(text))),text_split(text)\n",
    "        text_index.append(t1[0])\n",
    "        text_value.append(sum(t1[0]))\n",
    "    return text_index[text_value.index(min(text_value))]\n",
    "\n",
    "def test_news(text):\n",
    "    answer=[]\n",
    "    for i,text_ in enumerate(text):\n",
    "        sentence = [vocab.piece_to_id(\"[CLS]\")] + [vocab.piece_to_id(p) for p in text_] + [vocab.piece_to_id(\"[SEP]\")]\n",
    "        segments=[i%2] * len(sentence)\n",
    "        sentence = torch.tensor(sentence).expand(1,-1).to(config.device)\n",
    "        segments = torch.tensor(segments).expand(1,-1).to(config.device)\n",
    "        answer.append(test_model(sentence, segments)[0][0][1])\n",
    "    return answer\n",
    "def text_split(text):\n",
    "    trim_text=[]\n",
    "    for s in text.split('.'):\n",
    "        cut_text = s.replace('\\n','')+'.'\n",
    "        if cut_text != '.':\n",
    "            trim_text.append(cut_text)\n",
    "    return trim_text\n",
    "\n",
    "def output_index(value_list):\n",
    "    answer=[]\n",
    "    ext_value = 0\n",
    "    if len(value_list)>15:\n",
    "        count = len(value_list)//5\n",
    "    else:\n",
    "        count = 3\n",
    "    for i in range(3):\n",
    "        max_value = value_list.index(max(value_list))\n",
    "        ext_value += max(value_list)\n",
    "        answer.append(max_value)\n",
    "        value_list.pop(max_value)\n",
    "        value_list.insert(max_value,float('-inf'))\n",
    "    return [answer,ext_value]\n",
    "\n",
    "def concat_text(index_list, sentence):\n",
    "    index_list.sort()\n",
    "    text = ''\n",
    "    for t in index_list:\n",
    "        text += sentence[t]\n",
    "    return text\n",
    "\n",
    "def ROUGUE(index_list, sentence):\n",
    "    index_list.sort()\n",
    "    text = []\n",
    "    for t in index_list:\n",
    "        text.append(sentence[t])\n",
    "    return text\n",
    "\n",
    "def EXTSentence(sentence):\n",
    "    return concat_text(find_max(sentence),text_split(sentence))\n",
    "#     return concat_text(output_index(test_news(text_split(a)))[0],text_split(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee007da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=\"\"\"\n",
    "\n",
    "국방부가 서울 용산에 있는 합동참모본부를 남태령으로 이전하는 비용 중 55억9000만원을 내년도 예산안에 포함하려 한 것으로 나타났다. 국방부·합참은 합참 이전 비용을 내년도 예산안에 편성해달라는 요구를 하지 않았다고 주장한 것으로 알려졌다. 실제 내년도 예산안에 반영된 합참 이전 비용은 전혀 없다. 예비타당성 조사까지 면제하며 내년도 예산안에 210억원이 편성된 방위사업청 이전과 달리 정부가 합참 이전 의지가 없다는 지적이 제기된다.\n",
    "\n",
    "4일 국회 국방위원회 소속 윤후덕 더불어민주당 의원이 합참으로부터 받은 자료를 보면, 합참은 내년도 예산안에 합참 이전 비용 중 55억9000만원을 반영해달라고 요구할 계획을 세웠다. 합참은 2024년 이후 합참 이전 예산에 건축비 2100억여원 등 추가 비용이 들 것으로 보고, 사전에 필요한 예산 일부를 먼저 반영해달라고 요청할 계획이었다. 그러나 기획재정부 심사 등을 거치는 과정에서 해당 요구안은 실제로 반영되지 않았다.\n",
    "\n",
    "윤 의원에 따르면 국방부와 합참은 “합참 이전 비용을 내년도 예산안에 요구하지 않았다”는 입장을 의원실에 전했다. 지난달 19일 국회 국방위원회 전체회의에서는 합참 이전 관련 비용이 내년도 예산안에 왜 반영되지 않았냐는 정성호 민주당 의원 질의에 김승겸 합참의장이 “사업 타당성 조사가 이뤄지지 않았다”고 답했다. 국방부 관계자는 기자에게도 “합참 이전 관련 내년도 예산안으로 요청한 바 없다. 사업타당성 조사가 끝난 후 요구할 예정”이라고 설명했다.\n",
    "\n",
    "이는 예비타당성 조사를 면제하며 내년도 예산안에 210억원을 편성한 방사청 이전 사업과 대조적이다. 윤석열 정부 출범 후 예비타당성 조사가 면제된 사업은 총 16건인데, 방사청 이전 외에도 육군 관사 등 시설 개선 사업이 6건이 추가로 포함됐지만 대통령실 용산 이전 후 필수적인 합참 이전 예산은 반영되지 않았다.\n",
    "\n",
    "윤후덕 의원은 “육군 관사, 방사청 이전보다 합참 이전이 덜 중요한 사업인지 묻지 않을 수 없다”며 “합참 이전이 내년 예산이 아니라 2024년 예산부터 반영되면 현 정부 내 완전 이전이 어려워 안보 공백과 혼란이 계속될까 우려된다”고 말했다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17202e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4일 국회 국방위원회 소속 윤후덕 더불어민주당 의원이 합참으로부터 받은 자료를 보면, 합참은 내년도 예산안에 합참 이전 비용 중 55억9000만원을 반영해달라고 요구할 계획을 세웠다.윤 의원에 따르면 국방부와 합참은 “합참 이전 비용을 내년도 예산안에 요구하지 않았다”는 입장을 의원실에 전했다.윤후덕 의원은 “육군 관사, 방사청 이전보다 합참 이전이 덜 중요한 사업인지 묻지 않을 수 없다”며 “합참 이전이 내년 예산이 아니라 2024년 예산부터 반영되면 현 정부 내 완전 이전이 어려워 안보 공백과 혼란이 계속될까 우려된다”고 말했다.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXTSentence(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7349cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'윤석열 대통령이 12일(한국시각) 밤 10에 화상으로 열리는 ‘제2차 글로벌 코로나19 정상회의’에 참석한다.화상형식이기는 하나 다자외교 무대에 데뷔하는 것이다.의제는 백신 접종, 진단검사와 치료제 접근 확대, 보건안보 강화와 미래 재난 방지를 위한 방안 등이다.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXTSentence(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "81653353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'서울=연합뉴스) 조민정 김영신 기자 = 방역당국이 확진자 수 감소 추세와 일반의료체계로의 전환을 고려해 지난달부터 코로나19 병상 2만656개를 지정 해제했다고 25일 밝혔다.다만 고위험 확진자의 빠른 입원·치료를 위해 중등증 환자를 위한 거점보유병상도 일부 유지하기로 했다.일각에서는 병상이 빠르게 감축되면서 하반기 재유행시 신속한 대응에 어려움을 겪을 수 있다는 지적이 나온다.'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXTSentence(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bd10da4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'친러 국가인 중국에서 러시아를 향한 비판이 나온 것은 이례적이다. 11일(현지시간) 영국 가디언에 따르면 가오위셩 전 우크라이나 주재 중국대사는 중국 사회과학원 온라인 세미나에서 “러시아의 (우크라이나 침공) 전쟁이 실패하고 있다”고 진단했다. 이번 전쟁으로 우크라이나가 오히려 러시아의 영향권에서 벗어나 서방에 더 가까워졌다고 그는 주장했다.'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXTSentence(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc73c5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'윤석열 대통령이 12일(한국시각) 밤 10에 화상으로 열리는 ‘제2차 글로벌 코로나19 정상회의’에 참석한다.윤석열 대통령이 12일 오후 서울 용산 대통령실 청사에서 추경 예산안 편성을 위한 첫 국무회의를 주재하고 있다.지난 10일 취임한 윤 대통령의 다자 정상회의 참가는 이번이 처음이다.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXTSentence(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9cd7a060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 친러 국가인 중국에서 러시아를 향한 비판이 나온 것은 이례적이다.',\n",
       " '11일(현지시간) 영국 가디언에 따르면 가오위셩 전 우크라이나 주재 중국대사는 중국 사회과학원 온라인 세미나에서 “러시아의 (우크라이나 침공) 전쟁이 실패하고 있다”고 진단했다.',\n",
       " '가오 전 대사는 “(우크라이나에서) 러시아의 정치ㆍ경제ㆍ군사ㆍ외교력이 급격히 약해지고 고립되는 새로운 세계 질서가 나타날 가능성이 높다”고 내다봤다.']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_split(EXTSentence(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dca0e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_original.json') as file:\n",
    "    data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5a50d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = json_normalize(data['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cda483c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>extractive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>논 타작물 재배, 2월 말까지 신청하세요</td>\n",
       "      <td>[[{'index': 0, 'sentence': 'ha당 조사료 400만원…작물별 ...</td>\n",
       "      <td>[2, 3, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>여수시, 컬러빌리지 마무리...‘색채와 빛’도시 완성</td>\n",
       "      <td>[[{'index': 0, 'sentence': '8억 투입, 고소천사벽화·자산마을...</td>\n",
       "      <td>[2, 4, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“새해 정기 받고 올해는 반드시 일내자!”</td>\n",
       "      <td>[[{'index': 0, 'sentence': '전남드래곤즈 해맞이 다짐…선수 영...</td>\n",
       "      <td>[3, 5, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>농업인 역량 강화, 새해 실용교육 실시</td>\n",
       "      <td>[[{'index': 0, 'sentence': '11~24일, 매실·감·참다래 등...</td>\n",
       "      <td>[2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>타이완 크루즈관광객 4천여명‘전남’온다</td>\n",
       "      <td>[[{'index': 0, 'sentence': '홍콩 크루즈선사‘아쿠아리우스’ 4...</td>\n",
       "      <td>[3, 7, 4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title  \\\n",
       "0         논 타작물 재배, 2월 말까지 신청하세요   \n",
       "1  여수시, 컬러빌리지 마무리...‘색채와 빛’도시 완성   \n",
       "2        “새해 정기 받고 올해는 반드시 일내자!”   \n",
       "3          농업인 역량 강화, 새해 실용교육 실시   \n",
       "4          타이완 크루즈관광객 4천여명‘전남’온다   \n",
       "\n",
       "                                                text  extractive  \n",
       "0  [[{'index': 0, 'sentence': 'ha당 조사료 400만원…작물별 ...  [2, 3, 10]  \n",
       "1  [[{'index': 0, 'sentence': '8억 투입, 고소천사벽화·자산마을...  [2, 4, 11]  \n",
       "2  [[{'index': 0, 'sentence': '전남드래곤즈 해맞이 다짐…선수 영...   [3, 5, 7]  \n",
       "3  [[{'index': 0, 'sentence': '11~24일, 매실·감·참다래 등...   [2, 3, 4]  \n",
       "4  [[{'index': 0, 'sentence': '홍콩 크루즈선사‘아쿠아리우스’ 4...   [3, 7, 4]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['title','text','extractive']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06cda704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                  | 200/243983 [00:00<00:01, 123561.76it/s]\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "answer=[]\n",
    "for index,ext in enumerate(tqdm(df['extractive'])):\n",
    "    if count==200: break\n",
    "    line=0\n",
    "    for i, text in enumerate(df['text'][index]):\n",
    "        for i_ in range(len(text)):\n",
    "            if line in ext:\n",
    "                sentence_=text[i_]['sentence']\n",
    "#                 sentence_=vocab.encode_as_pieces(sentence_)\n",
    "                answer.append(sentence_)\n",
    "            line+=1\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "153d16f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                   | 200/243983 [02:10<44:20:55,  1.53it/s]\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "valid=[]\n",
    "for index,ext in enumerate(tqdm(df['extractive'])):\n",
    "    if count==200: break\n",
    "    sentence=''\n",
    "    for i, text in enumerate(df['text'][index]):\n",
    "        for i_ in range(len(text)):\n",
    "            sentence_=text[i_]['sentence']\n",
    "            sentence_=re.sub(r\"[^\\uAC00-\\uD7A30-9a-zA-Z\\s]\", \"\", sentence_)\n",
    "            if len(sentence_)>500:\n",
    "                sentence_ = sentence_[len(sentence_)-500:len(sentence_)]\n",
    "            sentence += sentence_+'.\\n'\n",
    "    valid += text_split(EXTSentence(sentence))\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06cc6548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ha당 조사료 400만원작물별 차등 지원\\n이성훈 sinawihanmailnet\\n전라남도가 쌀 과잉문제를 근본적으로 해결하기 위해 올해부터 시행하는 쌀 생산조정제를 적극 추진키로 했다\\n쌀 생산조정제는 벼를 심었던 논에 벼 대신 사료작물이나 콩 등 다른 작물을 심으면 벼와의 일정 소득차를 보전해주는 제도다\\n올해 전남의 논 다른 작물 재배 계획면적은 전국 5만ha의 약 21인 1만 698ha로 세부시행지침을 확정 시군에 통보했다\\n지원사업 대상은 2017년산 쌀 변동직불금을 받은 농지에 10a300평 이상 벼 이외 다른 작물을 재배한 농업인이다\\n지원 대상 작물은 1년생을 포함한 다년생의 모든 작물이 해당되나 재배 면적 확대 시 수급과잉이 우려되는 고추 무 배추 인삼 대파 등 수급 불안 품목은 제외된다\\n농지의 경우도 이미 다른 작물 재배 의무가 부여된 간척지 정부매입비축농지 농진청 시범사업 경관보전 직불금 수령 농지 등은 제외될 예정이다\\nha3000평당 지원 단가는 평균 340만원으로 사료작물 400만원 일반작물은 340만원 콩팥 등 두류작물은 280만원 등이다\\n벼와 소득차와 영농 편이성을 감안해 작물별로 차등 지원된다\\n논에 다른 작물 재배를 바라는 농가는 오는 22일부터 2월 28일까지 농지 소재지 읍면동사무소에 신청해야 한다\\n전남도는 도와 시군에 관련 기관과 농가 등이 참여하는논 타작물 지원사업 추진협의회를 구성 지역 특성에 맞는 작목 선정 및 사업 심의 등을 본격 추진할 방침이다\\n최향철 전라남도 친환경농업과장은 최근 쌀값이 다소 상승추세에 있으나 매년 공급과잉에 따른 가격 하락으로 쌀농가에 어려움이 있었다며쌀 공급과잉을 구조적으로 해결하도록 논 타작물 재배 지원사업에 많이 참여해주길 바란다고 말했다\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62095328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43f75adc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b5b2dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이성훈 sinawi@hanmail.net\\n여수광양항만공사(사장 방희석, 이하 공사)는 2018년도 승진 및 전보 인사를 단행했다고 지난 26일 밝혔다.\\n공사는 광양항 활성화 및 물동량 창출을 위해‘항만운영팀’, ‘글로벌마케팅팀’, ‘물류단지팀’의 인력을 보강하고자 인사를 실시하게 됐다고 설명했다.\\n특히 정부 정책의 적극적인 이행과 일자리 창출 등 사회적 가치 실현을 위해‘가치경영팀’을 신설한 것도 이번 인사의 요인이라고 덧붙였다.\\n*2018년도 승진·전보 인사\\n<승진> ◇ 1급(실·팀장) △항만운영팀장 김한춘 ◇ 2급(부장) △항만개발팀장 고영찬 △재무회계팀 박정철 △물류단지팀 장방식 ◇ 3급(차장) △가치경영팀 박상우 △인재육성팀 박진수 △기획조정실 양헌모 △항만시설팀 고훈정 ◇ 4급(과장) △재무회계팀 임지현 △항만개발팀 권규하 ◇ 6급(주임) △경영지원팀 최민경 △항만운영팀 조현성 △가치경영팀 김세라 △글로벌마케팅팀 유창기 △항만운영팀 배순길 △물류단지팀 조보라 △여수사업소 채성석 ◇ 7급(가) △가치경영팀 양대송\\n<전보> ◇ 1급(실·팀장) △재무회계팀장 최연철 △항만개발팀 기술자문위원 권영원 ◇ 2급(부장) △기획조정실장 선정덕 △가치경영팀장 정기철 △글로벌마케팅팀장 백정원 △미래사업팀 조성래 △항만운영팀 천철웅 ◇ 3급(차장) △인재육성팀 윤승재 △기획조정실 이병홍 △기획조정실 김일영 △가치경영팀 박 신 △항만운영팀 손정국 △물류단지팀 권용재 △여수사업소 권석록 △감사팀 고우권 ◇ 4급(과장) △감사팀 정연형 △기획조정실 주성구 △항만운영팀 봉만식 △물류단지팀 조령래 ◇ 5급(대리) △미래사업팀 박경민 △가치경영팀 정혜성 △가치경영팀 허 철 △항만운영팀 나병제 ◇ 6급(주임) △감사팀 최진혁 △기획조정실 김민주 △경영지원팀 김지성 △가치경영팀 박여진 △여수사업소 배수현\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e6fdcaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.36190033273608163,\n",
       "  'p': 0.36686092248347146,\n",
       "  'f': 0.3626422845625625},\n",
       " 'rouge-2': {'r': 0.3346825396825397,\n",
       "  'p': 0.3321825396825397,\n",
       "  'f': 0.33329364896237507},\n",
       " 'rouge-l': {'r': 0.36190033273608163,\n",
       "  'p': 0.36686092248347146,\n",
       "  'f': 0.3626422845625625}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "rougue_test = Rouge()\n",
    "rougue_test.get_scores(valid[:len(answer)],answer,avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eae07ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.39083613625586333,\n",
       "  'p': 0.3947329808795855,\n",
       "  'f': 0.39102006440191206},\n",
       " 'rouge-2': {'r': 0.34512690525981526,\n",
       "  'p': 0.34610480978541963,\n",
       "  'f': 0.34544864838364303},\n",
       " 'rouge-l': {'r': 0.38876567745684504,\n",
       "  'p': 0.39226294833215364,\n",
       "  'f': 0.3888101790595631}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "rougue_test = Rouge()\n",
    "rougue_test.get_scores(valid[:len(answer)],answer,avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "206a5f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.36939979530311606,\n",
       "  'p': 0.3769749487968717,\n",
       "  'f': 0.3709373223607037},\n",
       " 'rouge-2': {'r': 0.316590138857307,\n",
       "  'p': 0.3182712260484179,\n",
       "  'f': 0.31704829620751407},\n",
       " 'rouge-l': {'r': 0.36767265883963485,\n",
       "  'p': 0.3750126258196026,\n",
       "  'f': 0.36919628504041263}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "rougue_test = Rouge()\n",
    "rougue_test.get_scores(valid[:len(answer)],answer,avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90250e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
