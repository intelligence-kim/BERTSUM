{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c17d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from random import random, randrange, randint, shuffle, choice\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm, tqdm_notebook, trange\n",
    "import sentencepiece as spm\n",
    "import wget\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba94c531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 GPU : cuda\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('학습 GPU :',device)\n",
    "print('cuda index:', torch.cuda.current_device())\n",
    "\n",
    "print('gpu 개수:', torch.cuda.device_count())\n",
    "\n",
    "print('graphic name:', torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a91cf69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vocab_file = \"/home/studio/바탕화면/web-crawler/kowiki/vocab_32000/kowiki.model\"\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(vocab_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ac6d03",
   "metadata": {},
   "source": [
    "![config](./image/config.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "354839fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict): \n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file):\n",
    "        with open(file, 'r') as f:\n",
    "            config = json.loads(f.read())\n",
    "            return Config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd90daa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_enc_vocab': 32007, 'n_enc_seq': 512, 'n_seg_type': 2, 'n_layer': 6, 'd_model': 512, 'i_pad': 0, 'd_ff': 1024, 'n_head': 6, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"
     ]
    }
   ],
   "source": [
    "config = Config({\n",
    "    \"n_enc_vocab\": len(vocab), # vocab 크기\n",
    "    \"n_enc_seq\": 512,          # 글자 최대 길이 \n",
    "    \"n_seg_type\": 2,           # Segment Embedding Type  \n",
    "    \"n_layer\":6,             # layer 캣수\n",
    "    \"d_model\": 512,            # hidden layer \n",
    "    \"i_pad\": 0,                # padding 값\n",
    "    \"d_ff\": 1024,              # feedforward layer에 들어갈 차원의 크기\n",
    "    \"n_head\": 6,              # attention 개수\n",
    "    \"d_head\": 64,              # attention 차원 \n",
    "    \"dropout\": 0.1,            # dropout\n",
    "    \"layer_norm_epsilon\": 1e-12 # 정규화\n",
    "})\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b50cdb",
   "metadata": {},
   "source": [
    "![pe](./image/pe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0bfb70",
   "metadata": {},
   "source": [
    "![pe2](./image/pe2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61254dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" positional encoding\"\"\"\n",
    "def get_sinusoid_encoding_table(n_seq, d_model):\n",
    "    def cal_angle(position, i_hidn):\n",
    "        return position / np.power(10000, 2 * (i_hidn // 2) / d_model)\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i_hidn) for i_hidn in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # even index sin \n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # odd index cos\n",
    "\n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12d4781",
   "metadata": {},
   "source": [
    "![pad](./image/pad.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da05fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" attention pad mask \"\"\"\n",
    "def get_attn_pad_mask(seq_q, seq_k, i_pad):\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    pad_attn_mask = seq_k.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)  # <pad>\n",
    "    return pad_attn_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e9d8e0",
   "metadata": {},
   "source": [
    "![sd](./image/sd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36338bd",
   "metadata": {},
   "source": [
    "![sd2](./image/sd2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93fe04ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" scale dot product attention \"\"\"\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.scale = 1 / (self.config.d_head ** 0.5)\n",
    "    \n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        # (bs, n_head, n_q_seq, n_k_seq)\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n",
    "        scores.masked_fill_(attn_mask, -1e9)\n",
    "        # (bs, n_head, n_q_seq, n_k_seq)\n",
    "        attn_prob = nn.Softmax(dim=-1)(scores)\n",
    "        attn_prob = self.dropout(attn_prob)\n",
    "        # (bs, n_head, n_q_seq, d_v)\n",
    "        context = torch.matmul(attn_prob, V)\n",
    "        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\n",
    "        return context, attn_prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb1de04",
   "metadata": {},
   "source": [
    "![mt](./image/multi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e4f235",
   "metadata": {},
   "source": [
    "![mt](./image/multi2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e2a2b8",
   "metadata": {},
   "source": [
    "![mt3](./image/multi3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5ce1b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" multi head attention \"\"\"\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.W_Q = nn.Linear(self.config.d_model, self.config.n_head * self.config.d_head)\n",
    "        self.W_K = nn.Linear(self.config.d_model, self.config.n_head * self.config.d_head)\n",
    "        self.W_V = nn.Linear(self.config.d_model, self.config.n_head * self.config.d_head)\n",
    "        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n",
    "        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_model)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "    \n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        batch_size = Q.size(0)\n",
    "        # (bs, n_head, n_q_seq, d_head)\n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
    "        # (bs, n_head, n_k_seq, d_head)\n",
    "        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
    "        # (bs, n_head, n_v_seq, d_head)\n",
    "        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
    "\n",
    "        # (bs, n_head, n_q_seq, n_k_seq)\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n",
    "\n",
    "        # (bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\n",
    "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n",
    "        # (bs, n_head, n_q_seq, h_head * d_head)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\n",
    "        # (bs, n_head, n_q_seq, e_embd)\n",
    "        output = self.linear(context)\n",
    "        output = self.dropout(output)\n",
    "        # (bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\n",
    "        return output, attn_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b719aa7f",
   "metadata": {},
   "source": [
    "![ff](./image/ff.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fc5571",
   "metadata": {},
   "source": [
    "![ff2](./image/ff2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e677c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" feed forward \"\"\"\n",
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=self.config.d_model, out_channels=self.config.d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_model, kernel_size=1)\n",
    "        self.active = F.gelu\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # (bs, d_ff, n_seq)\n",
    "        output = self.active(self.conv1(inputs.transpose(1, 2)))\n",
    "        # (bs, n_seq, d_hidn)\n",
    "        output = self.conv2(output).transpose(1, 2)\n",
    "        output = self.dropout(output)\n",
    "        # (bs, n_seq, d_hidn)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c548d1d",
   "metadata": {},
   "source": [
    "![encoder](./image/encoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d245fee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" encoder layer \"\"\"\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.self_attn = MultiHeadAttention(self.config)\n",
    "        self.layer_norm1 = nn.LayerNorm(self.config.d_model, eps=self.config.layer_norm_epsilon)\n",
    "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
    "        self.layer_norm2 = nn.LayerNorm(self.config.d_model, eps=self.config.layer_norm_epsilon)\n",
    "    \n",
    "    def forward(self, inputs, attn_mask):\n",
    "        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
    "        att_outputs, attn_prob = self.self_attn(inputs, inputs, inputs, attn_mask)\n",
    "        att_outputs = self.layer_norm1(inputs + att_outputs)\n",
    "        # (bs, n_enc_seq, d_hidn)\n",
    "        ffn_outputs = self.pos_ffn(att_outputs)\n",
    "        ffn_outputs = self.layer_norm2(ffn_outputs + att_outputs)\n",
    "        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
    "        return ffn_outputs, attn_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e47bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" encoder \"\"\"\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.enc_emb = nn.Embedding(self.config.n_enc_vocab, self.config.d_model)\n",
    "        self.pos_emb = nn.Embedding(self.config.n_enc_seq + 1, self.config.d_model)\n",
    "        self.seg_emb = nn.Embedding(self.config.n_seg_type, self.config.d_model)\n",
    "\n",
    "        self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
    "    \n",
    "    def forward(self, inputs, segments):\n",
    "        positions = torch.arange(inputs.size(1), device=inputs.device, dtype=inputs.dtype).expand(inputs.size(0), inputs.size(1)).contiguous() + 1\n",
    "        pos_mask = inputs.eq(self.config.i_pad)\n",
    "        positions.masked_fill_(pos_mask, 0)\n",
    "\n",
    "        # (bs, n_enc_seq, d_hidn)\n",
    "        outputs = self.enc_emb(inputs) + self.pos_emb(positions)  + self.seg_emb(segments)\n",
    "\n",
    "        # (bs, n_enc_seq, n_enc_seq)\n",
    "        attn_mask = get_attn_pad_mask(inputs, inputs, self.config.i_pad)\n",
    "\n",
    "        attn_probs = []\n",
    "        for layer in self.layers:\n",
    "            # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
    "            outputs, attn_prob = layer(outputs, attn_mask)\n",
    "            attn_probs.append(attn_prob)\n",
    "        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
    "        return outputs, attn_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e2d713",
   "metadata": {},
   "source": [
    "![model](./image/bert.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd878a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.encoder = Encoder(self.config)\n",
    "\n",
    "        self.linear = nn.Linear(config.d_model, config.d_model)\n",
    "        self.activation = torch.tanh\n",
    "    \n",
    "    def forward(self, inputs, segments):\n",
    "        # (bs, n_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
    "        outputs, self_attn_probs = self.encoder(inputs, segments)\n",
    "        # (bs, d_hidn)\n",
    "        outputs_cls = outputs[:, 0].contiguous()\n",
    "        outputs_cls = self.linear(outputs_cls)\n",
    "        outputs_cls = self.activation(outputs_cls)\n",
    "        # (bs, n_enc_seq, n_enc_vocab), (bs, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
    "        return outputs, outputs_cls, self_attn_probs\n",
    "    \n",
    "    def save(self, epoch, loss, path):\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"loss\": loss,\n",
    "            \"state_dict\": self.state_dict()\n",
    "        }, path)\n",
    "    \n",
    "    def load(self, path):\n",
    "        save = torch.load(path)\n",
    "        self.load_state_dict(save[\"state_dict\"])\n",
    "        return save[\"epoch\"], save[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7030ac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTPretrain(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.bert = BERT(self.config)\n",
    "        # classfier\n",
    "        self.projection_cls = nn.Linear(self.config.d_model, 2, bias=False)\n",
    "        # lm\n",
    "        self.projection_lm = nn.Linear(self.config.d_model, self.config.n_enc_vocab, bias=False)\n",
    "        self.projection_lm.weight = self.bert.encoder.enc_emb.weight\n",
    "    \n",
    "    def forward(self, inputs, segments):\n",
    "        # (bs, n_enc_seq, d_hidn), (bs, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
    "        outputs, outputs_cls, attn_probs = self.bert(inputs, segments)\n",
    "        # (bs, 2)\n",
    "        logits_cls = self.projection_cls(outputs_cls)\n",
    "        # (bs, n_enc_seq, n_enc_vocab)\n",
    "        logits_lm = self.projection_lm(outputs)\n",
    "        # (bs, n_enc_vocab), (bs, n_enc_seq, n_enc_vocab), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
    "        return logits_cls, logits_lm, attn_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e6eb318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_mask(tokens, mask_cnt, vocab_list):\n",
    "    cand_idx = []\n",
    "    for (i, token) in enumerate(tokens):\n",
    "        if token == \"[CLS]\" or token == \"[SEP]\":\n",
    "            continue\n",
    "        if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):\n",
    "            cand_idx[-1].append(i)\n",
    "        else:\n",
    "            cand_idx.append([i])\n",
    "    shuffle(cand_idx)\n",
    "\n",
    "    mask_lms = []\n",
    "    for index_set in cand_idx:\n",
    "        if len(mask_lms) >= mask_cnt:\n",
    "            break\n",
    "        if len(mask_lms) + len(index_set) > mask_cnt:\n",
    "            continue\n",
    "        for index in index_set:\n",
    "            masked_token = None\n",
    "            if random() < 0.8: # 80% replace with [MASK]\n",
    "                masked_token = \"[MASK]\"\n",
    "            else:\n",
    "                if random() < 0.5: # 10% keep original\n",
    "                    masked_token = tokens[index]\n",
    "                else: # 10% random word\n",
    "                    masked_token = choice(vocab_list)\n",
    "            mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
    "            tokens[index] = masked_token\n",
    "    mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
    "    mask_idx = [p[\"index\"] for p in mask_lms]\n",
    "    mask_label = [p[\"label\"] for p in mask_lms]\n",
    "\n",
    "    return tokens, mask_idx, mask_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6421616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_tokens(tokens_a, tokens_b, max_seq):\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_seq:\n",
    "            break\n",
    "\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            del tokens_a[0]\n",
    "        else:\n",
    "            tokens_b.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fa5ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_instances(docs, doc_idx, doc, n_seq, mask_prob, vocab_list):\n",
    "    # for CLS], [SEP], [SEP]\n",
    "    max_seq = n_seq - 3\n",
    "    tgt_seq = max_seq\n",
    "    \n",
    "    instances = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for i in range(len(doc)):\n",
    "        current_chunk.append(doc[i]) # line\n",
    "        current_length += len(doc[i])\n",
    "        if i == len(doc) - 1 or current_length >= tgt_seq:\n",
    "            if 0 < len(current_chunk):\n",
    "                a_end = 1\n",
    "                if 1 < len(current_chunk):\n",
    "                    a_end = randrange(1, len(current_chunk))\n",
    "                tokens_a = []\n",
    "                for j in range(a_end):\n",
    "                    tokens_a.extend(current_chunk[j])\n",
    "                \n",
    "                tokens_b = []\n",
    "                if len(current_chunk) == 1 or random() < 0.5:\n",
    "                    is_next = 0\n",
    "                    tokens_b_len = tgt_seq - len(tokens_a)\n",
    "                    random_doc_idx = doc_idx\n",
    "                    while doc_idx == random_doc_idx:\n",
    "                        random_doc_idx = randrange(0, len(docs))\n",
    "                    random_doc = docs[random_doc_idx]\n",
    "\n",
    "                    random_start = randrange(0, len(random_doc))\n",
    "                    for j in range(random_start, len(random_doc)):\n",
    "                        tokens_b.extend(random_doc[j])\n",
    "                else:\n",
    "                    is_next = 1\n",
    "                    for j in range(a_end, len(current_chunk)):\n",
    "                        tokens_b.extend(current_chunk[j])\n",
    "\n",
    "                trim_tokens(tokens_a, tokens_b, max_seq)\n",
    "                assert 0 < len(tokens_a)\n",
    "                assert 0 < len(tokens_b)\n",
    "\n",
    "                tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
    "                segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
    "\n",
    "                tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * mask_prob), vocab_list)\n",
    "\n",
    "                instance = {\n",
    "                    \"tokens\": tokens,\n",
    "                    \"segment\": segment,\n",
    "                    \"is_next\": is_next,\n",
    "                    \"mask_idx\": mask_idx,\n",
    "                    \"mask_label\": mask_label\n",
    "                }\n",
    "                instances.append(instance)\n",
    "\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb05de98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pretrain_data(vocab, in_file, out_file, count, n_seq, mask_prob):\n",
    "    vocab_list = []\n",
    "    for id in range(vocab.get_piece_size()):\n",
    "        if not vocab.is_unknown(id):\n",
    "            vocab_list.append(vocab.id_to_piece(id))\n",
    "\n",
    "    line_cnt = 0\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        for line in in_f:\n",
    "            line_cnt += 1\n",
    "    \n",
    "    docs = []\n",
    "    with open(in_file, \"r\") as f:\n",
    "        doc = []\n",
    "        with tqdm_notebook(total=line_cnt, desc=f\"Loading\") as pbar:\n",
    "            for i, line in enumerate(f):\n",
    "                line = line.strip()\n",
    "                if line == \"\":\n",
    "                    if 0 < len(doc):\n",
    "                        docs.append(doc)\n",
    "                        doc = []\n",
    "                        # 메모리 사용량을 줄이기 위해 100,000개만 처리 함\n",
    "#                         if 100000 < len(docs): break\n",
    "                else:\n",
    "                    pieces = vocab.encode_as_pieces(line)\n",
    "                    if 0 < len(pieces):\n",
    "                        doc.append(pieces)\n",
    "                pbar.update(1)\n",
    "        if doc:\n",
    "            docs.append(doc)\n",
    "\n",
    "    for index in range(count):\n",
    "        output = out_file.format(index)\n",
    "        if os.path.isfile(output): continue\n",
    "\n",
    "        with open(output, \"w\") as out_f:\n",
    "            with tqdm_notebook(total=len(docs), desc=f\"Making\") as pbar:\n",
    "                for i, doc in enumerate(docs):\n",
    "                    instances = create_pretrain_instances(docs, i, doc, n_seq, mask_prob, vocab_list)\n",
    "                    for instance in instances:\n",
    "                        out_f.write(json.dumps(instance))\n",
    "                        out_f.write(\"\\n\")\n",
    "                    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e887ac48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14480/1944541818.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  with tqdm_notebook(total=line_cnt, desc=f\"Loading\") as pbar:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbb16ed207b4e77964eb412a7177de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading:   0%|          | 0/3646856 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14480/1944541818.py:37: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  with tqdm_notebook(total=len(docs), desc=f\"Making\") as pbar:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ea8530f62d431188254baadfec7983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Making:   0%|          | 0/729280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c90ac61103b4d29ad6b6c9357ecd434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Making:   0%|          | 0/729280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8624d23a5e83434e9ff0875644b6035b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Making:   0%|          | 0/729280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be36cbbc52d54bb58ac558fdd064bc18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Making:   0%|          | 0/729280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0825c7b392534b988c717aebeb75f2b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Making:   0%|          | 0/729280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "in_file = f\"/home/studio/바탕화면/web-crawler/NIKL_NEWSPAPER_2021_v1.0/news.txt\"\n",
    "out_file = f\"news_bert\" + \"_{}.json\"\n",
    "count = 5\n",
    "n_seq = 512\n",
    "mask_prob = 0.15\n",
    "\n",
    "make_pretrain_data(vocab, in_file, out_file, count, n_seq, mask_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f879fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pretrain 데이터셋 \"\"\"\n",
    "class PretrainDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, vocab, infile):\n",
    "        self.vocab = vocab\n",
    "        self.labels_cls = []\n",
    "        self.labels_lm = []\n",
    "        self.sentences = []\n",
    "        self.segments = []\n",
    "\n",
    "        line_cnt = 0\n",
    "        with open(infile, \"r\") as f:\n",
    "            for line in f:\n",
    "                line_cnt += 1\n",
    "\n",
    "        with open(infile, \"r\") as f:\n",
    "            for i, line in enumerate(tqdm(f, total=line_cnt, desc=f\"Loading {infile}\", unit=\" lines\")):\n",
    "                instance = json.loads(line)\n",
    "                self.labels_cls.append(instance[\"is_next\"])\n",
    "                sentences = [vocab.piece_to_id(p) for p in instance[\"tokens\"]]\n",
    "                self.sentences.append(sentences)\n",
    "                self.segments.append(instance[\"segment\"])\n",
    "                mask_idx = np.array(instance[\"mask_idx\"], dtype=np.int)\n",
    "                mask_label = np.array([vocab.piece_to_id(p) for p in instance[\"mask_label\"]], dtype=np.int)\n",
    "                label_lm = np.full(len(sentences), dtype=np.int, fill_value=-1)\n",
    "                label_lm[mask_idx] = mask_label\n",
    "                self.labels_lm.append(label_lm)\n",
    "    \n",
    "    def __len__(self):\n",
    "        assert len(self.labels_cls) == len(self.labels_lm)\n",
    "        assert len(self.labels_cls) == len(self.sentences)\n",
    "        assert len(self.labels_cls) == len(self.segments)\n",
    "        return len(self.labels_cls)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return (torch.tensor(self.labels_cls[item]),\n",
    "                torch.tensor(self.labels_lm[item]),\n",
    "                torch.tensor(self.sentences[item]),\n",
    "                torch.tensor(self.segments[item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2addb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pretrain data collate_fn \"\"\"\n",
    "def pretrin_collate_fn(inputs):\n",
    "    labels_cls, labels_lm, inputs, segments = list(zip(*inputs))\n",
    "\n",
    "    labels_lm = torch.nn.utils.rnn.pad_sequence(labels_lm, batch_first=True, padding_value=-1)\n",
    "    inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n",
    "    segments = torch.nn.utils.rnn.pad_sequence(segments, batch_first=True, padding_value=0)\n",
    "\n",
    "    batch = [\n",
    "        torch.stack(labels_cls, dim=0),\n",
    "        labels_lm,\n",
    "        inputs,\n",
    "        segments\n",
    "    ]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e9157eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading news_bert_0.json:   0%|                  | 0/729280 [00:00<?, ? lines/s]/tmp/ipykernel_3199/1003407272.py:22: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask_idx = np.array(instance[\"mask_idx\"], dtype=np.int)\n",
      "/tmp/ipykernel_3199/1003407272.py:23: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask_label = np.array([vocab.piece_to_id(p) for p in instance[\"mask_label\"]], dtype=np.int)\n",
      "/tmp/ipykernel_3199/1003407272.py:24: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  label_lm = np.full(len(sentences), dtype=np.int, fill_value=-1)\n",
      "Loading news_bert_0.json: 100%|███| 729280/729280 [04:34<00:00, 2659.60 lines/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" pretrain 데이터 로더 \"\"\"\n",
    "batch_size = 32\n",
    "dataset = PretrainDataSet(vocab, f\"news_bert_0.json\")\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=pretrin_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "948fb46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 모델 epoch 학습 \"\"\"\n",
    "def train_epoch(config, epoch, model, criterion_lm, criterion_cls, optimizer, train_loader):\n",
    "    losses = []\n",
    "    model.train()\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n",
    "        for i, value in enumerate(train_loader):\n",
    "            labels_cls, labels_lm, inputs, segments = map(lambda v: v.to(config.device), value)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs, segments)\n",
    "            logits_cls, logits_lm = outputs[0], outputs[1]\n",
    "\n",
    "            loss_cls = criterion_cls(logits_cls, labels_cls)\n",
    "            loss_lm = criterion_lm(logits_lm.view(-1, logits_lm.size(2)), labels_lm.view(-1))\n",
    "            loss = loss_cls + loss_lm\n",
    "\n",
    "            loss_val = loss_lm.item()\n",
    "            losses.append(loss_val)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79310f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_enc_vocab': 32007, 'n_enc_seq': 512, 'n_seg_type': 2, 'n_layer': 6, 'd_model': 512, 'i_pad': 0, 'd_ff': 1024, 'n_head': 6, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': device(type='cuda')}\n"
     ]
    }
   ],
   "source": [
    "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(config)\n",
    "\n",
    "learning_rate = 5e-5\n",
    "n_epoch = 10\n",
    "count=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdfd0d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load pretrain from: save_bert_pretrain.pth, epoch=30, loss=4.036490649327525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train(31): 100%|███| 22790/22790 [1:18:39<00:00,  4.83it/s, Loss: 4.236 (3.982)]\n",
      "Loading news_bert_2.json:   0%|            | 0/729280 [00:00<?, ? lines/s]/tmp/ipykernel_3199/1003407272.py:22: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask_idx = np.array(instance[\"mask_idx\"], dtype=np.int)\n",
      "/tmp/ipykernel_3199/1003407272.py:23: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask_label = np.array([vocab.piece_to_id(p) for p in instance[\"mask_label\"]], dtype=np.int)\n",
      "/tmp/ipykernel_3199/1003407272.py:24: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  label_lm = np.full(len(sentences), dtype=np.int, fill_value=-1)\n",
      "Loading news_bert_2.json: 100%|█| 729280/729280 [04:54<00:00, 2477.02 line\n",
      "Train(32): 100%|█| 22790/22790 [1:17:54<00:00,  4.88it/s, Loss: 4.133 (3.9\n",
      "Loading news_bert_3.json: 100%|█| 729280/729280 [04:50<00:00, 2513.82 line\n",
      "Train(33): 100%|█| 22790/22790 [1:18:06<00:00,  4.86it/s, Loss: 3.980 (3.9\n",
      "Loading news_bert_4.json: 100%|█| 729280/729280 [04:57<00:00, 2449.97 line\n",
      "Train(34): 100%|█| 22790/22790 [1:18:34<00:00,  4.83it/s, Loss: 3.992 (3.8\n",
      "Loading news_bert_0.json: 100%|█| 729280/729280 [04:57<00:00, 2453.91 line\n",
      "Train(35): 100%|█| 22790/22790 [1:18:12<00:00,  4.86it/s, Loss: 3.755 (3.8\n",
      "Loading news_bert_1.json: 100%|█| 729280/729280 [04:59<00:00, 2433.48 line\n",
      "Train(36): 100%|█| 22790/22790 [1:18:35<00:00,  4.83it/s, Loss: 3.846 (3.8\n",
      "Loading news_bert_2.json: 100%|█| 729280/729280 [05:05<00:00, 2387.81 line\n",
      "Train(37): 100%|█| 22790/22790 [1:18:13<00:00,  4.86it/s, Loss: 3.648 (3.8\n",
      "Loading news_bert_3.json: 100%|█| 729280/729280 [04:54<00:00, 2479.52 line\n",
      "Train(38): 100%|█| 22790/22790 [1:18:30<00:00,  4.84it/s, Loss: 3.715 (3.7\n",
      "Loading news_bert_4.json: 100%|█| 729280/729280 [04:56<00:00, 2459.04 line\n",
      "Train(39): 100%|█| 22790/22790 [1:18:18<00:00,  4.85it/s, Loss: 3.795 (3.7\n",
      "Loading news_bert_0.json: 100%|█| 729280/729280 [05:00<00:00, 2427.78 line\n",
      "Train(40): 100%|█| 22790/22790 [1:18:34<00:00,  4.83it/s, Loss: 3.689 (3.7\n"
     ]
    }
   ],
   "source": [
    "model = BERTPretrain(config)\n",
    "\n",
    "save_pretrain = f\"save_bert_pretrain.pth\"\n",
    "best_epoch, best_loss = 0, 0\n",
    "if os.path.isfile(save_pretrain):\n",
    "    best_epoch, best_loss = model.bert.load(save_pretrain)\n",
    "    print(f\"load pretrain from: {save_pretrain}, epoch={best_epoch}, loss={best_loss}\")\n",
    "    best_epoch += 1\n",
    "\n",
    "model.to(config.device)\n",
    "\n",
    "criterion_lm = torch.nn.CrossEntropyLoss(ignore_index=-1, reduction='mean')\n",
    "criterion_cls = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "losses = []\n",
    "offset = best_epoch\n",
    "for step in range(n_epoch):\n",
    "    epoch = step + offset\n",
    "    if 0 < step:\n",
    "        del train_loader\n",
    "        dataset = PretrainDataSet(vocab, f\"news_bert_{epoch % count}.json\")\n",
    "        train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=pretrin_collate_fn)\n",
    "\n",
    "    loss = train_epoch(config, epoch, model, criterion_lm, criterion_cls, optimizer, train_loader)\n",
    "    losses.append(loss)\n",
    "    model.bert.save(epoch, loss, save_pretrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d658db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bb577d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
